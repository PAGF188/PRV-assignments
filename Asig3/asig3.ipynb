{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRV Assignment 3\n",
    "\n",
    "- Pablo Garcia Fernández"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial configuration\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import copy\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registration methodology\n",
    "\n",
    "Since the ICP registration algorithm needs an initial transformation that roughly aligns the source point cloud to the target point cloud (and a poor initial allignment might fail ICP convergence), the first step is to perform an initial guess through  global registration.\n",
    "\n",
    "Global registration methods do not require an alignment for initialization, but they usually produce poorer results. For this reason they are used as initialization of the local methods (like ICP). To perform the global registration we first downsample the point cloud using voxelization methods to structure the point cloud in 3D layers. Then, we estimate normals; and finally we compute FPFH feature for each point. This features are used (as in image alignment methods) to guess salient points and find correspondences between clouds.\n",
    "\n",
    "There are many features descriptors that can be used to describe point in clouds. Here we choose FPFH (Fast Point Feature Histograms), which is a robust multi-dimensional features which describe the local geometry around a point p for 3D point cloud *(R. B. Rusu, N. Blodow and M. Beetz, \"Fast Point Feature Histograms (FPFH) for 3D registration,\" 2009 IEEE International Conference on Robotics and Automation, 2009, pp. 3212-3217, doi: 10.1109/ROBOT.2009.5152473)* FPFH represent the underlying surface model properties at a point p through the combination of certain geometrical relations between p’s nearest k neighbors. The final output (for each point p) is a 33-dimensional vector that describes the local geometric property of p.\n",
    "\n",
    "\n",
    "Once the features are computed, RANSAC is used for global registration. In each RANSAC iteration, some points are picked from the source. Their corresponding points in the target point cloud are detected by querying the nearest neighbor in the 33-dimensional FPFH feature space. Finally a prune step is applied. The matches that pass the pruning step are used to compute the transformation between the clouds.\n",
    "\n",
    "As we have said, this initial transformation is not tight, so a local refinement must be done with ICP (Iterative Closest Point). Different ICP parameters and flavours (PointToPoint, PointToPlane) are tested to see its effect on the final alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions to perform the registration.\n",
    "# Some of these functions are based on open3D docs: \n",
    "# http://www.open3d.org/docs/latest/tutorial/Basic/icp_registration.html\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    \"\"\"\n",
    "    Visualizes a target point cloud and a source point cloud transformed with an alignment transformation. \n",
    "    The target point cloud and the source point cloud are painted with cyan and yellow colors respectively. \n",
    "    \"\"\"\n",
    "\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp],\n",
    "                                      zoom=0.4559,\n",
    "                                      front=[0.6452, -0.3036, -0.7011],\n",
    "                                      lookat=[1.9892, 2.0208, 1.8945],\n",
    "                                      up=[-0.2779, -0.9482, 0.1556])\n",
    "                                      \n",
    "\n",
    "def preprocess_point_cloud(pcd, voxel_size):\n",
    "    \"\"\"\n",
    "    Downsample the point cloud, estimate normals, then compute a FPFH feature for each point. \n",
    "    The FPFH feature is a 33-dimensional vector that describes the local geometric property of a point.\n",
    "    \n",
    "    > R. Rusu, N. Blodow, and M. Beetz, Fast Point Feature Histograms (FPFH) for 3D registration, ICRA, 2009.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Downsample with a voxel size %.3f.\" % voxel_size)\n",
    "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
    "\n",
    "    radius_normal = voxel_size * 2\n",
    "    print(\"Estimate normal with search radius %.3f.\" % radius_normal)\n",
    "    pcd_down.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "\n",
    "    radius_feature = voxel_size * 5\n",
    "    print(\"Compute FPFH feature with search radius %.3f.\" % radius_feature)\n",
    "    pcd_fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        pcd_down,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return pcd_down, pcd_fpfh\n",
    "\n",
    "\n",
    "def prepare_dataset(voxel_size, point_c1, point_c2, draw=False):\n",
    "    \"\"\"\n",
    "    Read a source point cloud and a target point cloud from two files. They are misaligned.\n",
    "    Estimate normals (needed for ICP point to plane)\n",
    "    Compute features.\n",
    "    \"\"\"\n",
    "    print(\"Load two point clouds.\")\n",
    "    source = o3d.io.read_point_cloud(point_c1)\n",
    "    target = o3d.io.read_point_cloud(point_c2)\n",
    "    \n",
    "    print(\"Estimate normals\")\n",
    "    source.estimate_normals()\n",
    "    target.estimate_normals()\n",
    "\n",
    "    if draw:\n",
    "        print(\"Initial misaligned:\")\n",
    "        draw_registration_result(source, target, np.identity(4))  # Show initial misaligned\n",
    "\n",
    "    source_down, source_fpfh = preprocess_point_cloud(source, voxel_size)\n",
    "    target_down, target_fpfh = preprocess_point_cloud(target, voxel_size)\n",
    "    return source, target, source_down, target_down, source_fpfh, target_fpfh\n",
    "\n",
    "\n",
    "def execute_global_registration(source_down, target_down, source_fpfh, target_fpfh, voxel_size):\n",
    "    \"\"\"\n",
    "    Global registration\n",
    "    \"\"\"\n",
    "    distance_threshold = voxel_size * 1.5\n",
    "    print(\"RANSAC registration on downsampled point clouds.\")\n",
    "    print(\"Since the downsampling voxel size is %.3f,\" % voxel_size)\n",
    "    print(\"we use a liberal distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "        source_down, target_down, source_fpfh, target_fpfh, True, distance_threshold,\n",
    "        o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "        4, [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(\n",
    "                0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(\n",
    "                distance_threshold)\n",
    "        ], o3d.pipelines.registration.RANSACConvergenceCriteria(4000000, 0.999))\n",
    "    return result\n",
    "\n",
    "\n",
    "def refine_registration(source, target, result_ransac, voxel_size, method=o3d.pipelines.registration.TransformationEstimationPointToPlane()):\n",
    "    \"\"\"\n",
    "    ICP registration. The input are two point clouds and an initial transformation (global registration result) that roughly \n",
    "    aligns the source point cloud to the target point cloud.\n",
    "    \n",
    "    We will try 2 main methods: PointToPoint and PointToPlane with different parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    distance_threshold = voxel_size * 0.4\n",
    "    print(\"Point-to-plane ICP registration is applied on original point\")\n",
    "    print(\"clouds to refine the alignment. This time we use a strict\")\n",
    "    print(\"distance threshold %.3f.\" % distance_threshold)\n",
    "    result = o3d.pipelines.registration.registration_icp(\n",
    "        source, target, distance_threshold, result_ransac.transformation,\n",
    "        method)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1\n",
    "\n",
    "First, using Cloud Compare we obtain the ground truth of the alignment. It will be used for evaluation purposes. To evaluate the quality of the computed registration transformation, we will used the distance (Frobenius norm) between the ground truth and the computed transformations. The lower the value, the better.\n",
    "\n",
    "$$\\left[\n",
    "\\begin{array}{ll}\n",
    "0.996401 & 0.083261 & 0.015885 & -1.239532 \\\\\n",
    "-0.083465 & 0.996431 & 0.012612 & 0.060150 \\\\\n",
    "-0.014778 & -0.013892 & 0.999795 & 0.013994 \\\\\n",
    "0.000000 & 0.000000 & 0.000000 & 1.000000 \\\\\n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "\n",
    "*Note: we include some images as attachments because open3d display methods do not allow us to show the result in the notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1: Baseline\n",
    "\n",
    "We perform the registration with default good parameters to obtain a baseline for comparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "point_cloud1_1 = \"./data1/000009.pcd\"\n",
    "point_cloud1_2 = \"./data1/000013.pcd\"\n",
    "\n",
    "gt_transf = np.array([\n",
    "            [0.996401, 0.083261, 0.015885, -1.239532],\n",
    "            [-0.083465, 0.996431, 0.012612, 0.060150],\n",
    "            [-0.014778, -0.013892, 0.999795, 0.013994],\n",
    "            [0.000000, 0.000000, 0.000000, 1.000000]\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare dataset, compute features and show initial misaligned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load two point clouds.\n",
      "Estimate normals\n",
      "Initial misaligned:\n",
      "Downsample with a voxel size 0.100.\n",
      "Estimate normal with search radius 0.200.\n",
      "Compute FPFH feature with search radius 0.500.\n",
      "Downsample with a voxel size 0.100.\n",
      "Estimate normal with search radius 0.200.\n",
      "Compute FPFH feature with search radius 0.500.\n",
      "\n",
      "!! Distance: 1.2469966877301641\n"
     ]
    }
   ],
   "source": [
    "voxel_size = 0.1\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size, point_cloud1_1, point_cloud1_2, True)\n",
    "\n",
    "# Compute initial alignmetn quality\n",
    "print(\"\\n!! Distance:\", np.linalg.norm(gt_transf - np.identity(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly see the misalignment, for example on the poster.\n",
    "\n",
    "<img src=\"./img/exp1_misalign.PNG\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform global registration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANSAC registration on downsampled point clouds.\n",
      "Since the downsampling voxel size is 0.100,\n",
      "we use a liberal distance threshold 0.150.\n",
      "\n",
      "Transformation:\n",
      "[[ 0.99624598  0.08456448  0.01851457 -1.31173011]\n",
      " [-0.08487046  0.99625677  0.01641519  0.04458664]\n",
      " [-0.01705712 -0.01792491  0.99969383  0.05159821]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "!! Distance: 0.08315911675431552\n",
      "Execution time:  3.080801248550415\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "fin = time.time()\n",
    "draw_registration_result(source_down, target_down, result_ransac.transformation)\n",
    "\n",
    "print(f\"\\nTransformation:\\n{result_ransac.transformation}\\n\")\n",
    "print(\"!! Distance:\", np.linalg.norm(gt_transf - result_ransac.transformation))\n",
    "print(\"Execution time: \", fin-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result has improved. Visually it can be seen in the post. Numerically in the decrease of the distance between the transformations.\n",
    "\n",
    "<img src=\"./img/exp1_global.PNG\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform ICP refinement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point-to-plane ICP registration is applied on original point\n",
      "clouds to refine the alignment. This time we use a strict\n",
      "distance threshold 0.040.\n",
      "\n",
      "Transformation:\n",
      "[[ 0.99632099  0.08366965  0.01854372 -1.31074271]\n",
      " [-0.08394143  0.99636669  0.01439606  0.01377643]\n",
      " [-0.01727184 -0.01589968  0.9997244   0.00972672]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "\n",
      "!! Distance: 0.08520912017003214\n",
      "Execution time:  0.3715336322784424\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result_icp = refine_registration(source, target, result_ransac, voxel_size, method=o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "fin = time.time()\n",
    "draw_registration_result(source, target, result_icp.transformation)\n",
    "\n",
    "print(f\"\\nTransformation:\\n{result_icp.transformation}\\n\")\n",
    "print(\"!! Distance:\", np.linalg.norm(gt_transf - result_icp.transformation))\n",
    "print(\"Execution time: \", fin-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result has improved (distance decreasing).\n",
    "\n",
    "<img src=\"./img/exp1_icp.PNG\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2: Voxel size effect\n",
    "\n",
    "Voxel size if a very important parameter when downsampling the point clouds. Lower voxel sizes are equivalent to higher resolution, while larger voxel sizes imply lower resolution. \n",
    "\n",
    "When performing global registration method, high-resolution downsampling (or equivalently small voxel sizes) leads to longer execution time and the possibility of falling into local minimums. \n",
    "\n",
    "This is what happens in the following example: the global registration time increase up to 16s, but transformation does not change.\n",
    "\n",
    "In this experiment we can also observed how a bad initial transformation guess for the ICP method, leads the algorithm not to converge and consequently to obtain a bad alignment. In this case the final transformation is almost the identity matrix (no minor differences with respect the initial positions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load two point clouds.\n",
      "Estimate normals\n",
      "Downsample with a voxel size 0.010.\n",
      "Estimate normal with search radius 0.020.\n",
      "Compute FPFH feature with search radius 0.050.\n",
      "Downsample with a voxel size 0.010.\n",
      "Estimate normal with search radius 0.020.\n",
      "Compute FPFH feature with search radius 0.050.\n",
      "\n",
      "!! Initial distance: 1.2469966877301641 \n",
      "\n",
      "\n",
      "> GLOBAL REGISTRATION!!!\n",
      "RANSAC registration on downsampled point clouds.\n",
      "Since the downsampling voxel size is 0.010,\n",
      "we use a liberal distance threshold 0.015.\n",
      "\n",
      "Transformation:\n",
      "[[1. 0. 0. 0.]\n",
      " [0. 1. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]]\n",
      "!! Distance: 1.2469966877301641\n",
      "Global registration time:  16.205626010894775 \n",
      "\n",
      "\n",
      "> ICP!!!\n",
      "Point-to-plane ICP registration is applied on original point\n",
      "clouds to refine the alignment. This time we use a strict\n",
      "distance threshold 0.004.\n",
      "Transformation:\n",
      "[[ 9.99999231e-01 -3.26017659e-04  1.19629756e-03 -5.18689945e-04]\n",
      " [ 3.25145636e-04  9.99999681e-01  7.29056972e-04 -9.74497241e-04]\n",
      " [-1.19653486e-03 -7.28667441e-04  9.99999019e-01  5.49619117e-03]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00  1.00000000e+00]]\n",
      "!! Distance: 1.2464791990448445\n",
      "ICP time:  0.23221039772033691\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 2 -> with lowe voxel size\n",
    "voxel_size = 0.01\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size, point_cloud1_1, point_cloud1_2)\n",
    "\n",
    "# Compute initial alignmetn quality\n",
    "print(\"\\n!! Initial distance:\", np.linalg.norm(gt_transf - np.identity(4)), \"\\n\\n\")\n",
    "\n",
    "print(\"> GLOBAL REGISTRATION!!!\")\n",
    "start = time.time()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "fin = time.time()\n",
    "print(f\"\\nTransformation:\\n{result_ransac.transformation}\")\n",
    "print(\"!! Distance:\", np.linalg.norm(gt_transf - result_ransac.transformation))\n",
    "print(\"Global registration time: \", fin-start, \"\\n\\n\")\n",
    "\n",
    "print(\"> ICP!!!\")\n",
    "start = time.time()\n",
    "result_icp = refine_registration(source, target, result_ransac, voxel_size, method=o3d.pipelines.registration.TransformationEstimationPointToPoint())\n",
    "fin = time.time()\n",
    "\n",
    "print(f\"Transformation:\\n{result_icp.transformation}\")\n",
    "print(\"!! Distance:\", np.linalg.norm(gt_transf - result_icp.transformation))\n",
    "print(\"ICP time: \", fin-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPERIMENT 3: ICP PointToPlane\n",
    "\n",
    "In the previous examples we were using the Point-To-Point ICP registration, where we first show a point-to-point ICP algorithm using the objective:\n",
    "\n",
    "$$E(T)=∑_{(p,q)∈K}∥p−T_q∥^2$$\n",
    "\n",
    "However, there is also another variant called Point-to-Plane that uses a different objective function:\n",
    "\n",
    "$$E(T)=∑(_{p,q)∈K}((p−T_q)⋅n_p)^2$$\n",
    "\n",
    "where n_p is the normal of point p. Equations extracted from http://www.open3d.org/docs/latest/tutorial/t_pipelines/t_icp_registration.html\n",
    "\n",
    "In this example we compare this alternative version with the baseline (experiment 1):\n",
    "\n",
    "- As we do not have the normals in the .pcd file, we first estimate them in the `prepare_dataset()` function.\n",
    "- The final distance shows how this method achieve a better registration result (less difference between the ground truth and the obtained transofmations) in a shoter time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load two point clouds.\n",
      "Estimate normals\n",
      "Downsample with a voxel size 0.100.\n",
      "Estimate normal with search radius 0.200.\n",
      "Compute FPFH feature with search radius 0.500.\n",
      "Downsample with a voxel size 0.100.\n",
      "Estimate normal with search radius 0.200.\n",
      "Compute FPFH feature with search radius 0.500.\n",
      "\n",
      "!! Initial distance: 1.2469966877301641 \n",
      "\n",
      "\n",
      "> GLOBAL REGISTRATION!!!\n",
      "RANSAC registration on downsampled point clouds.\n",
      "Since the downsampling voxel size is 0.100,\n",
      "we use a liberal distance threshold 0.150.\n",
      "\n",
      "Transformation:\n",
      "[[ 0.99605972  0.08640227  0.01999185 -1.29694619]\n",
      " [-0.08663592  0.99617786  0.01113043  0.00573418]\n",
      " [-0.01895374 -0.01281858  0.99973819  0.0356652 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "!! Distance: 0.08237030998686633\n",
      "Global registration time:  3.119835376739502 \n",
      "\n",
      "\n",
      "> ICP!!!\n",
      "Point-to-plane ICP registration is applied on original point\n",
      "clouds to refine the alignment. This time we use a strict\n",
      "distance threshold 0.040.\n",
      "Transformation:\n",
      "[[ 0.9963475   0.08336077  0.01851078 -1.30767851]\n",
      " [-0.08363019  0.99639439  0.01429046  0.01440695]\n",
      " [-0.01725277 -0.01578633  0.99972653  0.0091216 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "!! Distance: 0.0823382293063511\n",
      "ICP time:  0.3222925662994385\n"
     ]
    }
   ],
   "source": [
    "# EXPERIMENT 3 -> Point-To-Plane with good voxel size\n",
    "voxel_size = 0.1\n",
    "source, target, source_down, target_down, source_fpfh, target_fpfh = prepare_dataset(voxel_size, point_cloud1_1, point_cloud1_2)\n",
    "\n",
    "# Compute initial alignmetn quality\n",
    "print(\"\\n!! Initial distance:\", np.linalg.norm(gt_transf - np.identity(4)), \"\\n\\n\")\n",
    "\n",
    "print(\"> GLOBAL REGISTRATION!!!\")\n",
    "start = time.time()\n",
    "result_ransac = execute_global_registration(source_down, target_down,\n",
    "                                            source_fpfh, target_fpfh,\n",
    "                                            voxel_size)\n",
    "fin = time.time()\n",
    "print(f\"\\nTransformation:\\n{result_ransac.transformation}\")\n",
    "print(\"!! Distance:\", np.linalg.norm(gt_transf - result_ransac.transformation))\n",
    "print(\"Global registration time: \", fin-start, \"\\n\\n\")\n",
    "\n",
    "print(\"> ICP!!!\")\n",
    "start = time.time()\n",
    "result_icp = refine_registration(source, target, result_ransac, voxel_size, method=o3d.pipelines.registration.TransformationEstimationPointToPlane())  ### here!!!\n",
    "fin = time.time()\n",
    "\n",
    "print(f\"Transformation:\\n{result_icp.transformation}\")\n",
    "print(\"!! Distance:\", np.linalg.norm(gt_transf - result_icp.transformation))\n",
    "print(\"ICP time: \", fin-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATASET 2\n",
    "\n",
    "Falta ejecutar lo mismo que antes (sin experimentos solo base) con el dataset de clase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS\n",
    "\n",
    "- Point-To-Plane mejor que PtP tiempo\n",
    "- Importancia voxel size\n",
    "- Importancia ajuste inicial ICP"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "678785dc911158653c20f13b17075a2459096d8eb73829e6f945951932744b1f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('FIPA')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
